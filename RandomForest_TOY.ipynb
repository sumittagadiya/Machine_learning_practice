{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest_TOY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB7Y3NeQLvjj",
        "colab_type": "text"
      },
      "source": [
        "# **Random Forest With Toy Data**\n",
        "*   Random forest is an ensemble of decision tree algorithms.\n",
        "\n",
        "*   It is an extension of bootstrap aggregation (bagging) of decision trees and can be used for classification and regression problems.\n",
        "*   In bagging, a number of decision trees are created where each tree is created from a different bootstrap sample of the training dataset.\n",
        "*   A bootstrap sample is a sample of the training dataset where a sample may appear more than once in the sample, referred to as sampling with replacement.\n",
        "*   Predictions from the trees are averaged across all decision trees resulting in better performance than any single tree in the model.\n",
        "\n",
        "**Reference** : https://machinelearningmastery.com/random-forest-ensemble-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YZkS2-FLrSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c7f1e65-fe71-4388-9e6d-7ef35da56a60"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmomWDhkN5WA",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest with classification\n",
        "*   First, we will use the make_classification() function to create a synthetic binary classification problem with 1,000 examples and 20 input features.\n",
        "* make_classification() : https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RpBMJcDNoKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "15e47568-156c-4f5e-ad29-4c3f0a97a4af"
      },
      "source": [
        "# test classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)\n",
        "type(X)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 20) (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcF6OK73PQ8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f56ff08d-25f7-4122-9b37-1311c53c5a1b"
      },
      "source": [
        "print(X)\n",
        "#As we can see there are 1000 samples(Rows) and 20 features(columns) are there in data "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -8.52381793   5.24451077 -12.14967704 ...   1.05057966   0.6975331\n",
            "    0.26076035]\n",
            " [ -0.05916285  -3.54893654   0.28450157 ...   2.25695685   1.22878976\n",
            "   -2.35705572]\n",
            " [  1.43722964  -2.7930806    3.06777424 ...   7.17348666   2.7348798\n",
            "   -5.86519533]\n",
            " ...\n",
            " [  3.16342902  -9.33711497   9.98425127 ...  -2.10531942  -0.81155073\n",
            "   -1.87188942]\n",
            " [ -9.02657972   2.59981304  -4.6665526  ...  -1.4839017   -1.30836833\n",
            "    0.22976655]\n",
            " [ -2.91686079   2.27957528  -1.00615184 ...  -0.67922735  -2.84990903\n",
            "   -2.06836683]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_fUPYO0PXGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "bd2c2220-5feb-48c4-a41a-4fc7dafa3a24"
      },
      "source": [
        "print(y) \n",
        "#As we can see there are 2 classes in target feature.\n",
        "#we can make more then 2 class classification problem by giving setting value of n_classes in make_classification"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0\n",
            " 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 0\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0\n",
            " 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0\n",
            " 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 0 1\n",
            " 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1\n",
            " 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0\n",
            " 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
            " 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1\n",
            " 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1\n",
            " 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1\n",
            " 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0\n",
            " 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0\n",
            " 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0\n",
            " 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1\n",
            " 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1\n",
            " 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0\n",
            " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1\n",
            " 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMS5D6w_Qhfe",
        "colab_type": "text"
      },
      "source": [
        "*  **We will evaluate the model using repeated stratified k-fold cross-validation, with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jutuNzWIQ8Oe",
        "colab_type": "text"
      },
      "source": [
        "**Please Refer following links for more understanding**\n",
        "* cross_val_score : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
        "* RepeatedStratifiedKFold: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html\n",
        "* RandomForestClassifier()  : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPFjqgDZPqfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22cd2e91-11c5-41b7-e379-bf8f0d27a2c1"
      },
      "source": [
        "# evaluate random forest algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=25, n_informative=20, n_redundant=5, random_state=3)\n",
        "# define the model\n",
        "model = RandomForestClassifier()\n",
        "# evaluate the model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "#every time when run algorithm result may vary because of stochastic nature of learning algorithm"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.907 (0.034)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpFt39Cbsko2",
        "colab_type": "text"
      },
      "source": [
        "**To make prediction for classification First, the random forest ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB6xj8rSr62e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40ca1315-6bc1-4f53-faf3-194ebdfe2ad7"
      },
      "source": [
        "# make predictions using random forest for classification\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "# define the model\n",
        "model = RandomForestClassifier()\n",
        "# fit the model on the whole dataset\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "#here we are prediction on single sample same way we can predict when we have test data in real world\n",
        "row = [[-8.52381793,5.24451077,-12.14967704,-2.92949242,0.99314133,0.67326595,-0.38657932,1.27955683,-0.60712621,3.20807316,0.60504151,-1.38706415,8.92444588,-7.43027595,-2.33653219,1.10358169,0.21547782,1.05057966,0.6975331,0.26076035]]\n",
        "yhat = model.predict(row)\n",
        "print('Predicted Class: %d' % yhat[0])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9MvjLActQ4b",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest for regression\n",
        "*  First, we can use the make_regression() function to create a synthetic regression problem with 1,000 examples and 20 input features.\n",
        "* **make_regression()** : https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24FP72XJs6VZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c061ad82-5421-4bab-a718-085f064ca968"
      },
      "source": [
        "# test regression dataset\n",
        "from sklearn.datasets import make_regression\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=30, n_informative=25, noise=0.1, random_state=2)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 30) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbAwYqOvw1M6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "89e7086c-9c58-4763-90d6-c5932ca2e053"
      },
      "source": [
        "print(X)  #data with 1000 samples(rows) and 30 features(columns)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.26701202e+00  1.32441809e+00  4.42677115e-01 ... -2.84081199e-01\n",
            "  -5.78804087e-01 -2.46932549e-01]\n",
            " [-7.05819970e-01 -1.70012060e-01  6.04344101e-01 ... -4.67016251e-02\n",
            "  -4.62142098e-01  2.70344069e-01]\n",
            " [ 8.65072824e-01 -1.09401380e-01 -1.38215062e+00 ... -1.84724568e+00\n",
            "   2.42625947e-01  1.49484284e+00]\n",
            " ...\n",
            " [-1.91247129e+00 -2.37674786e+00 -5.61144223e-01 ...  7.78416508e-01\n",
            "  -3.38627529e-01 -9.43300023e-01]\n",
            " [-9.57559083e-01 -4.37132565e-01 -3.51826978e-01 ...  8.58199428e-01\n",
            "  -7.26032272e-01 -1.14894528e-01]\n",
            " [-4.96432932e-02  1.14081588e-01 -2.68005109e-01 ...  6.04599295e-04\n",
            "   6.39248784e-01  8.85120896e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD0BMYL5xULm",
        "colab_type": "text"
      },
      "source": [
        "* **we will evaluate the model using repeated k-fold cross-validation, with three repeats and 10 folds. We will report the mean absolute error (MAE) of the model across all repeats and folds.**\n",
        "\n",
        "* **The scikit-learn library makes the MAE negative so that it is maximized instead of minimized. This means that larger negative MAE are better and a perfect model has a MAE of 0.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF5vNY9sw45-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e216b332-04c9-49c4-c3ed-fe1e551667e8"
      },
      "source": [
        "# evaluate random forest ensemble for regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=2)\n",
        "# define the model\n",
        "model = RandomForestRegressor()\n",
        "# evaluate the model\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: -90.660 (8.141)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsipCz2kzFxQ",
        "colab_type": "text"
      },
      "source": [
        "* In this case, we can see the random forest ensemble with default hyperparameters achieves a MAE of about 90.\n",
        "* We can also use the random forest model as a final model and make predictions for regression.\n",
        "\n",
        "* First, the random forest ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
        "\n",
        "* The example below demonstrates this on our regression dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaBGMObQxCo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d29e41aa-ace2-4e23-8e25-9cc1f3f31076"
      },
      "source": [
        "# random forest for making predictions for regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=2)\n",
        "# define the model\n",
        "model = RandomForestRegressor()\n",
        "# fit the model on the whole dataset\n",
        "model.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [[-0.89483109,-1.0670149,-0.25448694,-0.53850126,0.21082105,1.37435592,0.71203659,0.73093031,-1.25878104,-2.01656886,0.51906798,0.62767387,0.96250155,1.31410617,-1.25527295,-0.85079036,0.24129757,-0.17571721,-1.11454339,0.36268268]]\n",
        "yhat = model.predict(row)\n",
        "print('Prediction: %d' % yhat[0])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: -147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc3qgPp6ztrA",
        "colab_type": "text"
      },
      "source": [
        "*  specific results may vary given the stochastic nature of the learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYMXqSBLzwwq",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest HyperParameters\n",
        "* ## Explore Number of samples\n",
        "  *  Each decision tree in the ensemble is fit on a bootstrap sample drawn from the training dataset.\n",
        "\n",
        "  *  This can be turned off by setting the “bootstrap” argument to False, if you desire. In that case, the whole training dataset will be used to train each decision tree. This is not recommended.\n",
        "  * The “max_samples” argument can be set to a float between 0 and 1 to control the percentage of the size of the training dataset to make the bootstrap sample used to train each decision tree.\n",
        "  * For example, if the training dataset has 100 rows, the max_samples argument could be set to 0.5 and each decision tree will be fit on a bootstrap sample with (100 * 0.5) or 50 rows of data.\n",
        "  * A smaller sample size will make trees more different, and a larger sample size will make the trees more similar. Setting max_samples to “None” will make the sample size the same size as the training dataset and this is the default.\n",
        "  * The example below demonstrates the effect of different bootstrap sample sizes from 10 percent to 100 percent on the random forest algorithm.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFICNSmWzdVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "5cc857d9-707e-41cd-88c9-c182ea5a48b7"
      },
      "source": [
        "# explore random forest bootstrap sample size on performance\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['10'] = RandomForestClassifier(max_samples=0.1)\n",
        "\tmodels['20'] = RandomForestClassifier(max_samples=0.2)\n",
        "\tmodels['30'] = RandomForestClassifier(max_samples=0.3)\n",
        "\tmodels['40'] = RandomForestClassifier(max_samples=0.4)\n",
        "\tmodels['50'] = RandomForestClassifier(max_samples=0.5)\n",
        "\tmodels['60'] = RandomForestClassifier(max_samples=0.6)\n",
        "\tmodels['70'] = RandomForestClassifier(max_samples=0.7)\n",
        "\tmodels['80'] = RandomForestClassifier(max_samples=0.8)\n",
        "\tmodels['90'] = RandomForestClassifier(max_samples=0.9)\n",
        "\tmodels['100'] = RandomForestClassifier(max_samples=None)\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.xticks(rotation=45)\n",
        "pyplot.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">10 0.855 (0.035)\n",
            ">20 0.876 (0.024)\n",
            ">30 0.879 (0.025)\n",
            ">40 0.891 (0.027)\n",
            ">50 0.897 (0.026)\n",
            ">60 0.894 (0.025)\n",
            ">70 0.899 (0.028)\n",
            ">80 0.900 (0.023)\n",
            ">90 0.902 (0.024)\n",
            ">100 0.901 (0.027)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY1xN8aW2MJS",
        "colab_type": "text"
      },
      "source": [
        "* **In this case, the results suggest that using a bootstrap sample size that is equal to the size of the training dataset achieves the best results on this dataset.**\n",
        "\n",
        "* **A box and whisker plot is created for the distribution of accuracy scores for each bootstrap sample size.**\n",
        "\n",
        "* **In this case, we can see a general trend that the larger the sample, the better the performance of the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90DDXo6l3V1c",
        "colab_type": "text"
      },
      "source": [
        "##  **Explore Number of features**\n",
        "\n",
        "* The number of features that is randomly sampled for each split point is perhaps the most important feature to configure for random forest.\n",
        "\n",
        "* It is set via the max_features argument and defaults to the square root of the number of input features. In this case, for our test dataset, this would be sqrt(20) or about four features.\n",
        "\n",
        "* The example below explores the effect of the number of features randomly selected at each split point on model accuracy. We will try values from 1 to 7 and would expect a small value, around four, to perform well based on the heuristic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31AFnETt3XfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "a55384db-0d5b-488f-80a8-9d615dd66abc"
      },
      "source": [
        "# explore random forest number of features effect on performance\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['1'] = RandomForestClassifier(max_features=1)\n",
        "\tmodels['2'] = RandomForestClassifier(max_features=2)\n",
        "\tmodels['3'] = RandomForestClassifier(max_features=3)\n",
        "\tmodels['4'] = RandomForestClassifier(max_features=4)\n",
        "\tmodels['5'] = RandomForestClassifier(max_features=5)\n",
        "\tmodels['6'] = RandomForestClassifier(max_features=6)\n",
        "\tmodels['7'] = RandomForestClassifier(max_features=7)\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1 0.890 (0.028)\n",
            ">2 0.903 (0.027)\n",
            ">3 0.903 (0.032)\n",
            ">4 0.900 (0.025)\n",
            ">5 0.904 (0.025)\n",
            ">6 0.897 (0.023)\n",
            ">7 0.902 (0.022)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5LIFP8e4g_0",
        "colab_type": "text"
      },
      "source": [
        "* In this case, the results suggest that a value between three and five would be appropriate, confirming the sensible default of four on this dataset.\n",
        "* A value of five might even be better given the smaller standard deviation in classification accuracy as compared to a value of three or four.\n",
        "* A box and whisker plot is created for the distribution of accuracy scores for each feature set size.\n",
        "* We can see a trend in performance rising and peaking with values between three and five and falling again as larger feature set sizes are considered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb6TtoFh44-a",
        "colab_type": "text"
      },
      "source": [
        "## **Explore Number Of Trees**\n",
        "* The number of trees is another key hyperparameter to configure for the random forest.\n",
        "\n",
        "* Typically, the number of trees is increased until the model performance stabilizes. \n",
        "* Intuition might suggest that more trees will lead to overfitting, although this is not the case. Both bagging and random forest algorithms appear to be somewhat immune to overfitting the training dataset given the stochastic nature of the learning algorithm.\n",
        "\n",
        "* The number of trees can be set via the “n_estimators” argument and defaults to 100.\n",
        "\n",
        "* The example below explores the effect of the number of trees with values between 10 to 1,000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdgXzbhc1mGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "684b98b7-fa38-4acb-b619-5457a81261dd"
      },
      "source": [
        "# explore random forest number of trees effect on performance\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['10'] = RandomForestClassifier(n_estimators=10)\n",
        "\tmodels['50'] = RandomForestClassifier(n_estimators=50)\n",
        "\tmodels['100'] = RandomForestClassifier(n_estimators=100)\n",
        "\tmodels['500'] = RandomForestClassifier(n_estimators=500)\n",
        "\tmodels['1000'] = RandomForestClassifier(n_estimators=1000)\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">10 0.870 (0.032)\n",
            ">50 0.898 (0.031)\n",
            ">100 0.901 (0.027)\n",
            ">500 0.904 (0.023)\n",
            ">1000 0.904 (0.023)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_PT6yAa6Da5",
        "colab_type": "text"
      },
      "source": [
        "* **In this case, we can see that performance rises and stays flat after about 100 trees. Mean accuracy scores fluctuate across 100, 500, and 1,000 trees and this may be statistical noise.** \n",
        "* **Default value of n_estimator in RandomForestClassifier is 100**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daD6iMku6N3I",
        "colab_type": "text"
      },
      "source": [
        "## **Explore Tree Depth**\n",
        "* A final interesting hyperparameter is the maximum depth of decision trees used in the ensemble.\n",
        "\n",
        "* By default, trees are constructed to an arbitrary depth and are not pruned. This is a sensible default, although we can also explore fitting trees with different fixed depths.\n",
        "\n",
        "* The maximum tree depth can be specified via the max_depth argument and is set to None (no maximum depth) by default.\n",
        "\n",
        "* The example below explores the effect of random forest maximum tree depth on model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSG02u2S5zBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "15e2231c-2356-43b2-a88d-3e9923f02b45"
      },
      "source": [
        "# explore random forest tree depth effect on performance\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['1'] = RandomForestClassifier(max_depth=1)\n",
        "\tmodels['2'] = RandomForestClassifier(max_depth=2)\n",
        "\tmodels['3'] = RandomForestClassifier(max_depth=3)\n",
        "\tmodels['4'] = RandomForestClassifier(max_depth=4)\n",
        "\tmodels['5'] = RandomForestClassifier(max_depth=5)\n",
        "\tmodels['6'] = RandomForestClassifier(max_depth=6)\n",
        "\tmodels['7'] = RandomForestClassifier(max_depth=7)\n",
        "\tmodels['None'] = RandomForestClassifier(max_depth=None)\n",
        "\treturn models\n",
        " \n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1 0.772 (0.033)\n",
            ">2 0.810 (0.035)\n",
            ">3 0.835 (0.025)\n",
            ">4 0.851 (0.029)\n",
            ">5 0.872 (0.025)\n",
            ">6 0.882 (0.024)\n",
            ">7 0.892 (0.021)\n",
            ">None 0.904 (0.023)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR98hSoB7oGy",
        "colab_type": "text"
      },
      "source": [
        "* In this case, we can see that larger depth results in better model performance, with the default of no maximum depth achieving the best performance on this dataset.\n",
        "* A box and whisker plot is created for the distribution of accuracy scores for each configured maximum tree depth.\n",
        "\n",
        "* In this case, we can see a trend of improved performance with increase in tree depth, supporting the default of no maximum depth."
      ]
    }
  ]
}